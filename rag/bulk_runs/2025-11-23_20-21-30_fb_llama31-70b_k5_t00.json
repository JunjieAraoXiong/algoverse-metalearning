{
  "total_questions": 150,
  "successful_predictions": 150,
  "failed_predictions": 0,
  "success_rate": 100.0,
  "avg_semantic_similarity": 0.43153153767560276,
  "min_semantic_similarity": 0.08262566577769218,
  "max_semantic_similarity": 0.9999988552449627,
  "similarity_by_type": {
    "domain-relevant": {
      "mean": 0.5295514385549343,
      "count": 50,
      "min": 0.08995667917724884,
      "max": 0.9999988552449627
    },
    "metrics-generated": {
      "mean": 0.37365758631078405,
      "count": 50,
      "min": 0.10438661844338815,
      "max": 0.8740059974573005
    },
    "novel-generated": {
      "mean": 0.3913855881610902,
      "count": 50,
      "min": 0.08262566577769218,
      "max": 0.7758739301155926
    }
  },
  "avg_retrieval_time_ms": 598.5666195551554,
  "avg_generation_time_ms": 1134.2448043823242,
  "config": {
    "dataset_name": "financebench",
    "model_name": "meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo",
    "embedding_model": "text-embedding-3-large",
    "top_k_retrieval": 5,
    "use_hybrid_search": true,
    "use_metadata_filtering": true,
    "use_reranking": true,
    "temperature": 0.0,
    "max_tokens": 512,
    "use_llm_judge": true,
    "judge_model": "meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo",
    "chroma_path": "/Users/hansonxiong/Desktop/algoverse/shawheen rag/chroma",
    "output_dir": "/Users/hansonxiong/Desktop/algoverse/shawheen rag/bulk_runs",
    "timestamp": "2025-11-23_20-21-30"
  }
}